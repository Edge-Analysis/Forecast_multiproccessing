{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Forecasting Model\n",
    "\n",
    "## This forecasting model does the following:\n",
    " 1. Runs several models on training data to determine the most accurate forecast\n",
    " 2. Builds out a two-year forecast using the best forecast model\n",
    " 3. Graphs the forecast with confidence intervals\n",
    " 4. Returns a data export to excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) - Import Packages\n",
    "Imports required packages for modeling, analysis, and graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import stdev\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "from pmdarima import auto_arima\n",
    "from dateutil.relativedelta import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii) - Organize data\n",
    "Splits data into various DataFrames by heirarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df):\n",
    "    \"\"\"\n",
    "    Splits a 3-hierarchy DataFrame into seperate forecasting DataFrames\n",
    "    \n",
    "    Arguments:\n",
    "    df -- DataFrame to be split\n",
    "    \n",
    "    Returns:\n",
    "    top_df -- DataFrame for the top 'total' hierarchy\n",
    "    mid_df -- DataFrame for the middle hierarchy\n",
    "    mid_list -- list of each value in the middle hierarchy\n",
    "    mid_cnt -- count of values in the middle hierarchy\n",
    "    low_dfs -- dictionary containing all lower DataFrames\n",
    "    low_lists -- dictionary containing all lower values\n",
    "    low_cnts -- dictionary containing all lower value counts\n",
    "    \"\"\"\n",
    "    \n",
    "    # Top df\n",
    "    top_df = df.groupby(df.columns[2]).sum().rename(columns={df.columns[3]: 'total'})\n",
    "\n",
    "    # Mid df\n",
    "    mid_df = df.groupby([df.columns[0],df.columns[2]], as_index=False).sum()\n",
    "    mid_list = mid_df[df.columns[0]].unique()\n",
    "    mid_cnt = mid_df[df.columns[0]].nunique()\n",
    "    mid_df = mid_df.pivot(index = df.columns[2], columns = df.columns[0], values = df.columns[3])\n",
    "    mid_df = pd.concat([top_df, mid_df], axis=1, sort=False)\n",
    "\n",
    "    # Bottom dfs\n",
    "    low_df = df.groupby([df.columns[0],df.columns[1],df.columns[2]], as_index=False).sum()\n",
    "    low_dfs = {}\n",
    "    low_lists = {}\n",
    "    low_cnts = {}\n",
    "\n",
    "    for i in range(0,mid_cnt):\n",
    "\n",
    "        low_dfi = low_df.copy()\n",
    "        low_dfi = low_dfi[low_dfi[low_dfi.columns[0]] == mid_list[i]]\n",
    "        low_lists[\"low_list\" + str(i)] = low_dfi[low_dfi.columns[1]].unique()\n",
    "        low_cnts[\"low_cnt\" + str(i)] = low_dfi[low_dfi.columns[1]].nunique()\n",
    "\n",
    "        low_dfi = low_dfi.pivot(index = low_dfi.columns[2], columns = low_dfi.columns[1], values = df.columns[3])\n",
    "        low_dfs[\"low_df\" + str(i)] = pd.concat([mid_df.iloc[:,[i+1]], low_dfi], axis=1, sort=False)\n",
    "    \n",
    "    return top_df, mid_df, mid_list, mid_cnt, low_dfs, low_lists, low_cnts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Training Model\n",
    "Creates a training and test set from the data for out-of-sample testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(variable):\n",
    "    \"\"\"\n",
    "    Creates a training and test set from the data.\n",
    "    \n",
    "    Arguments:\n",
    "    variable -- array to be forecasted\n",
    "    \n",
    "    Returns:\n",
    "    trainset -- dataset with the testset removed\n",
    "    testset -- dataset used for testing forecast accuracy\n",
    "    testsize -- int showing the size of the testset\n",
    "    \"\"\"\n",
    "    \n",
    "    #calculate testsize:\n",
    "    if variable.index.size >=36:\n",
    "        testsize = 12\n",
    "    else:\n",
    "        testsize = int(36 - variable.index.size)\n",
    "        \n",
    "    ##test periods override:\n",
    "    testsize = 6\n",
    "    \n",
    "    #create training/learning sets\n",
    "    trainset = variable[0:variable.index.size - testsize]\n",
    "    testset = variable[variable.index.size - testsize:]\n",
    "    \n",
    "    return trainset, testset, testsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Testing Model\n",
    "Forecasts the 12 Holt-Winters exponential smoothing models and seasonal auto-ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(trainset, testset, testsize):\n",
    "    \"\"\"\n",
    "    Forecasts the 12 Holt-Winters exponential smoothing models and seasonal auto-ARIMA model\n",
    "    \n",
    "    Arguments:\n",
    "    trainset -- DataFrame to be forecasted\n",
    "    testset -- DataFrame for forecast to be tested against\n",
    "    testsize -- size of the testset (int)\n",
    "    \n",
    "    Returns:\n",
    "    fcst_results -- DataFrame containing all forecast results\n",
    "    \n",
    "    \"\"\"\n",
    "    fcst_results = testset.copy()\n",
    "    \n",
    "    #Run the 12 Exponential Smoothing (Holt-Winters) forecasting models\n",
    "    try:\n",
    "        \n",
    "        fit_MN = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend='mul', damped=False, seasonal=None,).fit()\n",
    "        fit_MA = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend='mul', damped=False, seasonal='add',).fit()\n",
    "        fit_MM = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend='mul', damped=False, seasonal='mul',).fit()\n",
    "        fit_NN = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend=None, damped=False, seasonal=None,).fit()\n",
    "        fit_NA = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend=None, damped=False, seasonal='add',).fit()\n",
    "        fit_NM = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend=None, damped=False, seasonal='mul',).fit()\n",
    "        fit_LN = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend='add', damped=False, seasonal=None,).fit()\n",
    "        fit_LA = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend='add', damped=False, seasonal='add',).fit()\n",
    "        fit_LM = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend='add', damped=False, seasonal='mul',).fit()\n",
    "        fit_DN = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend='add', damped=True, seasonal=None,).fit()\n",
    "        fit_DA = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend='add', damped=True, seasonal='add',).fit()\n",
    "        fit_DM = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend='add', damped=True, seasonal='mul',).fit()\n",
    "        \n",
    "        #Create a table of all the forecasts\n",
    "        fcst_results['NM_y_hat'] = fit_NM.forecast(testsize)\n",
    "        fcst_results['LM_y_hat'] = fit_LM.forecast(testsize)\n",
    "        fcst_results['DM_y_hat'] = fit_DM.forecast(testsize)\n",
    "        fcst_results['MN_y_hat'] = fit_MN.forecast(testsize)\n",
    "        fcst_results['MA_y_hat'] = fit_MA.forecast(testsize)\n",
    "        fcst_results['MM_y_hat'] = fit_MM.forecast(testsize)\n",
    "        \n",
    "    except NotImplementedError:\n",
    "        \n",
    "        fit_NN = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend=None, damped=False, seasonal=None,).fit()\n",
    "        fit_NA = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend=None, damped=False, seasonal='add',).fit()\n",
    "        fit_LN = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend='add', damped=False, seasonal=None,).fit()\n",
    "        fit_LA = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend='add', damped=False, seasonal='add',).fit()\n",
    "        fit_DN = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend='add', damped=True, seasonal=None,).fit()\n",
    "        fit_DA = ExponentialSmoothing(np.asarray(trainset) ,seasonal_periods=12 ,trend='add', damped=True, seasonal='add',).fit()\n",
    "        \n",
    "        #Create a table of all the forecasts\n",
    "        fcst_results['NM_y_hat'] = None\n",
    "        fcst_results['LM_y_hat'] = None\n",
    "        fcst_results['DM_y_hat'] = None\n",
    "        fcst_results['MN_y_hat'] = None\n",
    "        fcst_results['MA_y_hat'] = None\n",
    "        fcst_results['MM_y_hat'] = None\n",
    "\n",
    "    finally:\n",
    "        #Run the seasonal Auto-ARIMA (Box-Jenkins) forecast model\n",
    "        stepwise_model = auto_arima(trainset, start_p=1, start_q=1,\n",
    "                                   max_p=3, max_q=3, m=12,\n",
    "                                   start_P=1, seasonal=True,\n",
    "                                   error_action='ignore',\n",
    "                                   suppress_warnings=True,\n",
    "                                   stepwise=True)\n",
    "\n",
    "        stepwise_model.fit(np.asarray(trainset))\n",
    "        fit_ARIMA = stepwise_model.predict(testsize)\n",
    "        \n",
    "        #Create a table of all the forecasts\n",
    "        fcst_results['NN_y_hat'] = fit_NN.forecast(testsize)\n",
    "        fcst_results['NA_y_hat'] = fit_NA.forecast(testsize)\n",
    "        fcst_results['LN_y_hat'] = fit_LN.forecast(testsize)\n",
    "        fcst_results['LA_y_hat'] = fit_LA.forecast(testsize)\n",
    "        fcst_results['DN_y_hat'] = fit_DN.forecast(testsize)\n",
    "        fcst_results['DA_y_hat'] = fit_DA.forecast(testsize)\n",
    "        fcst_results['ARIMA_y_hat'] = fit_ARIMA\n",
    "    \n",
    "        return fcst_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Accuracy Model\n",
    "Calculates the error, MAPE, and standard deviation for each model and selects the best forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_model(fcst_results, testsize, override=False, or_season=False):\n",
    "    \"\"\"\n",
    "    Calculates the error, MAPE, and standard deviation for each model and selects the best forecast\n",
    "    \n",
    "    Arguments:\n",
    "    fcst_results -- DataFrame containing forecast results\n",
    "    testsize -- int showing the size of the testset\n",
    "    override -- optional string, override the forecast\n",
    "    or_season -- optional string, override forecast seasonality\n",
    "    \n",
    "    Returns:\n",
    "    best_fcst -- String signifying the winning model\n",
    "    fcst_error -- Percentage error for the best forecast\n",
    "    bf_stddev -- Int standard deviation of the errors for the best forecast\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #Caluculates the absolute error for each forecast period\n",
    "    variable = fcst_results.columns[0]\n",
    "    \n",
    "    fcst_results['NN_E'] = abs(fcst_results[variable] - fcst_results['NN_y_hat'])\n",
    "    fcst_results['NA_E'] = abs(fcst_results[variable] - fcst_results['NA_y_hat'])\n",
    "    fcst_results['NM_E'] = abs(fcst_results[variable] - fcst_results['NM_y_hat'])\n",
    "    fcst_results['LN_E'] = abs(fcst_results[variable] - fcst_results['LN_y_hat'])\n",
    "    fcst_results['LA_E'] = abs(fcst_results[variable] - fcst_results['LA_y_hat'])\n",
    "    fcst_results['LM_E'] = abs(fcst_results[variable] - fcst_results['LM_y_hat'])\n",
    "    fcst_results['DN_E'] = abs(fcst_results[variable] - fcst_results['DN_y_hat'])\n",
    "    fcst_results['DA_E'] = abs(fcst_results[variable] - fcst_results['DA_y_hat'])\n",
    "    fcst_results['DM_E'] = abs(fcst_results[variable] - fcst_results['DM_y_hat'])\n",
    "    fcst_results['MN_E'] = abs(fcst_results[variable] - fcst_results['MN_y_hat'])\n",
    "    fcst_results['MA_E'] = abs(fcst_results[variable] - fcst_results['MA_y_hat'])\n",
    "    fcst_results['MM_E'] = abs(fcst_results[variable] - fcst_results['MM_y_hat'])\n",
    "    fcst_results['ARIMA_E'] = abs(fcst_results[variable] - fcst_results['ARIMA_y_hat'])\n",
    "    \n",
    "    #Caluculates Absolute Percentage Error (APE) for each forecast period\n",
    "    \n",
    "    fcst_results['NN_APE'] = fcst_results['NN_E'] / fcst_results[variable]\n",
    "    fcst_results['NA_APE'] = fcst_results['NA_E'] / fcst_results[variable]\n",
    "    fcst_results['NM_APE'] = fcst_results['NM_E'] / fcst_results[variable]\n",
    "    fcst_results['LN_APE'] = fcst_results['LN_E'] / fcst_results[variable]\n",
    "    fcst_results['LA_APE'] = fcst_results['LA_E'] / fcst_results[variable]\n",
    "    fcst_results['LM_APE'] = fcst_results['LM_E'] / fcst_results[variable]\n",
    "    fcst_results['DN_APE'] = fcst_results['DN_E'] / fcst_results[variable]\n",
    "    fcst_results['DA_APE'] = fcst_results['DA_E'] / fcst_results[variable]\n",
    "    fcst_results['DM_APE'] = fcst_results['DM_E'] / fcst_results[variable]\n",
    "    fcst_results['MN_APE'] = fcst_results['MN_E'] / fcst_results[variable]\n",
    "    fcst_results['MA_APE'] = fcst_results['MA_E'] / fcst_results[variable]\n",
    "    fcst_results['MM_APE'] = fcst_results['MM_E'] / fcst_results[variable]\n",
    "    fcst_results['ARIMA_APE'] = fcst_results['ARIMA_E'] / fcst_results[variable]\n",
    "    \n",
    "    #Calculates the Mean Absolute Percentage Error (MAPE) for each forecast\n",
    "\n",
    "    mape = pd.DataFrame({'Model': ['NN','NA','NM','LN','LA','LM',\n",
    "                                    'DN','DA','DM','MN','MA','MM','ARIMA'],\n",
    "\n",
    "                         'Error': [sum(fcst_results['NN_E']),\n",
    "                                   sum(fcst_results['NA_E']),\n",
    "                                   sum(fcst_results['NM_E']),\n",
    "                                   sum(fcst_results['LN_E']),\n",
    "                                   sum(fcst_results['LA_E']),\n",
    "                                   sum(fcst_results['LM_E']),\n",
    "                                   sum(fcst_results['DN_E']),\n",
    "                                   sum(fcst_results['DA_E']),\n",
    "                                   sum(fcst_results['DM_E']),\n",
    "                                   sum(fcst_results['MN_E']),\n",
    "                                   sum(fcst_results['MA_E']),\n",
    "                                   sum(fcst_results['MM_E']),\n",
    "                                   sum(fcst_results['ARIMA_E'])],                               \n",
    "\n",
    "                          'MAPE':[sum(fcst_results['NN_APE'])/testsize,\n",
    "                                  sum(fcst_results['NA_APE'])/testsize,\n",
    "                                  sum(fcst_results['NM_APE'])/testsize,\n",
    "                                  sum(fcst_results['LN_APE'])/testsize,\n",
    "                                  sum(fcst_results['LA_APE'])/testsize,\n",
    "                                  sum(fcst_results['LM_APE'])/testsize,\n",
    "                                  sum(fcst_results['DN_APE'])/testsize,\n",
    "                                  sum(fcst_results['DA_APE'])/testsize,\n",
    "                                  sum(fcst_results['DM_APE'])/testsize,\n",
    "                                  sum(fcst_results['MN_APE'])/testsize,\n",
    "                                  sum(fcst_results['MA_APE'])/testsize,\n",
    "                                  sum(fcst_results['MM_APE'])/testsize,\n",
    "                                  sum(fcst_results['ARIMA_APE'])/testsize],\n",
    "\n",
    "                          'e_stdev':[stdev(fcst_results['NN_E']),\n",
    "                                  stdev(fcst_results['NA_E']),\n",
    "                                  stdev(fcst_results['NM_E']),\n",
    "                                  stdev(fcst_results['LN_E']),\n",
    "                                  stdev(fcst_results['LA_E']),\n",
    "                                  stdev(fcst_results['LM_E']),\n",
    "                                  stdev(fcst_results['DN_E']),\n",
    "                                  stdev(fcst_results['DA_E']),\n",
    "                                  stdev(fcst_results['DM_E']),\n",
    "                                  stdev(fcst_results['MN_E']),\n",
    "                                  stdev(fcst_results['MA_E']),\n",
    "                                  stdev(fcst_results['MM_E']),\n",
    "                                  stdev(fcst_results['ARIMA_E'])]})\n",
    "    \n",
    "    #Selects the winning forecast or override\n",
    "    \n",
    "    if override == False:\n",
    "        try:\n",
    "            best_fcst = mape.iloc[mape['MAPE'].idxmin(),0]\n",
    "        except TypeError:\n",
    "            best_fcst = mape.iloc[mape['Error'].idxmin(),0]\n",
    "            \n",
    "    else:\n",
    "        best_fcst = override\n",
    "\n",
    "    if or_season == False:\n",
    "        pass\n",
    "    else:\n",
    "        if best_fcst == 'ARIMA':\n",
    "            pass\n",
    "        else:\n",
    "            best_fcst = best_fcst[0] + or_season\n",
    "            \n",
    "    fcst_index = mape.index[mape['Model'] == best_fcst][0]\n",
    "    fcst_error = round(mape.iloc[fcst_index,2],2)\n",
    "    bf_stdev = mape.iloc[fcst_index,3]\n",
    "    \n",
    "    return best_fcst, fcst_error, bf_stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Forecast Model\n",
    "Builds the final forecast model using the best forecast and complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcst_model(fcst_df, best_fcst, d0):\n",
    "    \"\"\"\n",
    "    Builds the final forecast model using the best forecast and complete dataset\n",
    "    \n",
    "    Arguments:\n",
    "    fcst_df -- DataFrame to be forecasted\n",
    "    best_fcst -- String of winning forecast model (or override)\n",
    "    d0 -- Date of final historical month\n",
    "    \n",
    "    Returns:\n",
    "    history -- DataFrame containing all history\n",
    "    forecast -- DataFrame containing the final forecast\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #Trend\n",
    "    if best_fcst[0][0] == 'N':\n",
    "        trnd = None\n",
    "    else:\n",
    "        if best_fcst[0][0] == 'M':\n",
    "            trnd = 'mul'\n",
    "        else:\n",
    "            trnd = 'add'\n",
    "\n",
    "    #Dampening\n",
    "    if best_fcst[0][0] == 'D':\n",
    "        dmpd = True\n",
    "    else:\n",
    "        dmpd = False\n",
    "\n",
    "    #Seasonality\n",
    "    if best_fcst[1][0] == 'N':\n",
    "        season = None\n",
    "    else:\n",
    "        if best_fcst[0][0] == 'M':\n",
    "            season = 'mul'\n",
    "        else:\n",
    "            season = 'add'\n",
    "\n",
    "    #Final Forecast\n",
    "    if best_fcst == 'ARIMA':\n",
    "        \n",
    "        stepwise_model = auto_arima(fcst_df, start_p=1, start_q=1,\n",
    "                                   max_p=3, max_q=3, m=12,\n",
    "                                   start_P=1, seasonal=True,\n",
    "                                   error_action='ignore',\n",
    "                                   suppress_warnings=True,\n",
    "                                   stepwise=True)\n",
    "        \n",
    "        stepwise_model.fit(np.asarray(fcst_df))\n",
    "        fit_best = stepwise_model.predict(24)\n",
    "\n",
    "    else:\n",
    "        fit_best = ExponentialSmoothing(np.asarray(fcst_df), seasonal_periods=12, trend=trnd, damped=dmpd, seasonal=season,).fit()\n",
    "        fit_best = fit_best.forecast(24)\n",
    "    \n",
    "    #Add Dates to final forecast\n",
    "    fin_df = fcst_df\n",
    "    variable = fcst_df.columns[0]\n",
    "    \n",
    "    for i in range(fit_best.size):\n",
    "        next_month = d0 + relativedelta(months=+i+1)\n",
    "\n",
    "        fcst_period = pd.DataFrame([[next_month, fit_best[i]]], columns=['Month',variable]).set_index('Month')\n",
    "\n",
    "        fin_df = fin_df.append(fcst_period, sort=True)\n",
    "    \n",
    "    #Final DataFrames\n",
    "    d1 = fin_df.index.max()\n",
    "    \n",
    "    history = fin_df[0:fcst_df.size].copy()\n",
    "    forecast = fin_df[fcst_df.size:].copy()\n",
    "    \n",
    "    forecast[forecast.columns[0]] = [0 if i < 0 else i for i in forecast[forecast.columns[0]]]\n",
    "    \n",
    "    return history, forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 (optional) - Topdown Model\n",
    "Reallocates 'bottom' forecasts based on percentage of total 'top' forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_fcst(data, prev_fcst, error, top_column, bot_first, bot_last, topdown=False):\n",
    "    \"\"\"\n",
    "    Topdown = False: Forces top forecast to equal the sum of bottom forecasts\n",
    "    Topdown = True: Reallocates 'bottom' forecasts based on percentage of total 'top' forecast\n",
    "    \n",
    "    Arguments:\n",
    "    data -- DataFrame to be reallocated\n",
    "    prev_fcst -- DataFrame of origional testing/training forecast\n",
    "    error -- DataFrame showing the MAPE, stdev, and model for the origional forecast\n",
    "    top_column -- Column that contains the top forecast\n",
    "    bot_first -- first column of 'bottom' forecast range\n",
    "    bot_last: -- last column of 'bottom' forecast range (must be in order)\n",
    "    \n",
    "    Returns:\n",
    "    fin_data -- DataFrame altered to contain the reallocated forecast\n",
    "    fcst_error -- DataFrame showing the new MAPE, stdev, and model for the reallocated forecast\n",
    "    \"\"\"\n",
    "    dataset = data.copy()\n",
    "    re_testset = dataset[:dataset.index.size - 24].copy()\n",
    "    fcst_cache = prev_fcst.copy()\n",
    "    fcst_error = error.copy()\n",
    "    #mape_new = fcst_cache[:1].copy().reset_index().drop(columns='Month')\n",
    "    \n",
    "    #Recalculate testing/training MAPE using a top-down forecast\n",
    "    trainset, testset, testsize = train_model(re_testset)\n",
    "    \n",
    "    fcst_cache['xTotalx'] = fcst_cache.iloc[:,bot_first:bot_last].sum(axis=1)\n",
    "    \n",
    "    dataset['xTotalx'] = dataset.iloc[:,bot_first:bot_last].sum(axis=1)\n",
    "    \n",
    "    \n",
    "    if topdown == False:\n",
    "        #Bottom-up Model\n",
    "        fcst_cache['xTotalx_AE'] = abs(testset.iloc[:,top_column] - fcst_cache['xTotalx'])\n",
    "        fcst_cache['xTotalx_APE'] = fcst_cache['xTotalx_AE'] / testset.iloc[:,top_column]\n",
    "        fcst_error.iloc[0:,top_column] = round(sum(fcst_cache['xTotalx_APE'])/testsize,2)\n",
    "        fcst_error.iloc[1:,top_column] = round(stdev(fcst_cache['xTotalx_AE']),2)\n",
    "        fcst_error.iloc[2:,top_column] = \"Aggregate\"\n",
    "        \n",
    "        dataset.iloc[:,top_column] = dataset['xTotalx']\n",
    "        dataset.drop(dataset.columns[[bot_first,bot_last]], axis=1, inplace = True)\n",
    "                \n",
    "    else:\n",
    "        #Topdown Model\n",
    "        for i in range(bot_first, bot_last):\n",
    "            fcst_cache.iloc[:,i] = fcst_cache.iloc[:,i] / fcst_cache['xTotalx'] * fcst_cache.iloc[:,top_column]\n",
    "            fcst_cache[fcst_cache.columns[i]+'_AE'] = abs(testset.iloc[:,i] - fcst_cache.iloc[:,i])\n",
    "            fcst_cache[fcst_cache.columns[i]+'_APE'] = fcst_cache[fcst_cache.columns[i]+'_AE'] / testset.iloc[:,i]\n",
    "            fcst_error.iloc[0,i] = round(sum(fcst_cache[fcst_cache.columns[i]+'_APE'])/testsize,2)\n",
    "            fcst_error.iloc[1,i] = round(stdev(fcst_cache[fcst_cache.columns[i]+'_AE']),2)\n",
    "            fcst_error.iloc[2,i] = str(fcst_error.iloc[2,i]) + \" Topdown\"\n",
    "\n",
    "        for i in range(bot_first, bot_last):\n",
    "            dataset.iloc[:,i] = dataset.iloc[:,i] / dataset['xTotalx'] * dataset.iloc[:,top_column]\n",
    "\n",
    "        dataset.drop(dataset.columns[top_column], axis=1, inplace = True)\n",
    "    \n",
    "    dataset.drop(columns='xTotalx', inplace = True)\n",
    "    fin_data = dataset.copy()\n",
    "    \n",
    "    return fin_data, fcst_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 (optional) - Plot Forecast\n",
    "Builds the final forecast model using the best forecast and complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_fcst(history, forecast, best_fcst, MAPE, bf_stdev, division):\n",
    "    \"\"\"\n",
    "    Builds the final forecast model using the best forecast and complete dataset\n",
    "    \n",
    "    Arguments:\n",
    "    hours -- DataFrame to be forecasted\n",
    "    best_fcst -- String of winning forecast model (or override)\n",
    "    d0 -- Date of final historical month\n",
    "    \n",
    "    Returns:\n",
    "    history -- DataFrame containing all history\n",
    "    forecast -- DataFrame containing the final forecast\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    forecast['upper'] = forecast.iloc[:,[0]] + (2 * bf_stdev)\n",
    "    forecast['lower'] = forecast.iloc[:,[0]] - (2 * bf_stdev)\n",
    "\n",
    "    forecast['upper'] = [0 if i < 0 else i for i in forecast['upper']]\n",
    "    forecast['lower'] = [0 if i < 0 else i for i in forecast['lower']]\n",
    "    \n",
    "    #Plot history and forecast\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.plot(history, 'g-', label='History')\n",
    "    plt.plot(forecast.iloc[:,[0]], 'ro--', label=best_fcst+' Forecast')\n",
    "    \n",
    "    forecast['upper'].plot(kind='area', style='b:', label='_nolegend_')\n",
    "    forecast['lower'].plot(kind='area', style = 'w:', label='_nolegend_')\n",
    "    plt.plot(forecast['lower'], 'b:', label='95% conf')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.axis(ymin=0)\n",
    "    plt.grid(True)\n",
    "    plt.axvspan(forecast.index[0], forecast.index.max(), alpha=0.9, color='lightgrey')\n",
    "    plt.title(division+\": Model = \"+best_fcst+\", MAPE = \"+MAPE, fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Model\n",
    "Combines all forecasting models for ease of running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fcst(df_slice,override_fcst=False,override_seasonality=False,plot=True):\n",
    "    \"\"\"\n",
    "    Runs the complete testing,training,forecasting model\n",
    "    \n",
    "    Arguments:\n",
    "    df_slice -- DataFrame to be forecasted\n",
    "    override_fcst -- String to specify model name for best forecast override (default=False)\n",
    "    override_seaonality -- String to specify seasonality to override forecast (default=False)\n",
    "    plot: -- Boolean to specify if the forecast should be plotted (default=True)\n",
    "    \n",
    "    Returns:\n",
    "    history -- DataFrame containing all history\n",
    "    forecast -- DataFrame containing the final forecast\n",
    "    fcst_cache -- DataFrame containing the test forecast\n",
    "    fcst_error -- String containing the forecast MAPE\n",
    "    bf_stdev -- String containing the standard deviation of errors\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    #Training Model\n",
    "    trainset, testset, testsize = train_model(df_slice)\n",
    "    \n",
    "    #Forecasting Model\n",
    "    fcst_results = test_model(trainset, testset, testsize)\n",
    "    \n",
    "    #Testing Model\n",
    "    best_fcst, fcst_error, bf_stdev = acc_model(fcst_results, testsize, override=override_fcst, or_season=override_seasonality)\n",
    "    \n",
    "    #Final Forecast\n",
    "    history, forecast = fcst_model(df_slice, best_fcst, df_slice.index.max())\n",
    "    \n",
    "    #Plot Forecast\n",
    "    if plot == True:\n",
    "        plt_fcst(history, forecast, best_fcst, \"{0:.0f}%\".format(fcst_error * 100), bf_stdev, df_slice.columns[0])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    forecast = forecast.drop(columns=forecast.columns[1:3])\n",
    "    fcst_cache = fcst_results[best_fcst+'_y_hat'].to_frame().set_index(fcst_results.index)\n",
    "    fcst_cache.columns=[df_slice.columns[0]]\n",
    "    \n",
    "    error = pd.DataFrame({df_slice.columns[0]: [float(fcst_error),round(bf_stdev,2),best_fcst]}, index=['MAPE','stdev','model'])\n",
    "    \n",
    "    return history, forecast, fcst_cache, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Run\n",
    "Runs the forecast models using real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and organize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Capacity Forecast Data.xlsx', sheet_name='Dataset', parse_dates=['Month'])\n",
    "\n",
    "# Data organizer\n",
    "top_df, mid_df, mid_list, mid_cnt, low_dfs, low_lists, low_cnts = data_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forecast for the top hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "history, forecast, fcst_cache, error = run_fcst(top_df,override_fcst=False,override_seasonality=False,plot=True)\n",
    "\n",
    "top_fcst = history.append(forecast, sort=True)\n",
    "top_fcst.columns=['total']\n",
    "\n",
    "fcst_error = error.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forecasts for the middle hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mid_fcst = top_fcst.copy()\n",
    "\n",
    "for i in range(0, mid_cnt):\n",
    "    mid = mid_list[i]\n",
    "    history, forecast, mid_cache, error = run_fcst(mid_df.iloc[:,[i + 1]],override_fcst=False,override_seasonality=False,plot=True)\n",
    "    \n",
    "    mid_fcst[mid] = history.append(forecast, sort=True)\n",
    "    fcst_error[mid] = error\n",
    "    \n",
    "    fcst_cache[mid] = mid_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test override\n",
    "#override_name = 'Production Systems'\n",
    "#override_df = mid_df.loc[:,[override_name]]\n",
    "#history, forecast, mid_cache, error = run_fcst(override_df,override_fcst='DA',override_seasonality=False,plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottom-up reallocation of the middle hierarcy to the top hierarcy (replacing origional forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fcst, error = allocate_fcst(mid_fcst, fcst_cache, fcst_error, 0, 1, mid_cnt, topdown=False)\n",
    "fcst_hist = new_fcst[:new_fcst.index.size - 24].copy()\n",
    "fcst_new  = new_fcst[new_fcst.index.size - 24:].copy()\n",
    "\n",
    "mid_fcst.iloc[:,[0]] = fcst_hist.iloc[:,[0]].append(fcst_new.iloc[:,[0]])\n",
    "fcst_error = error.copy()\n",
    "\n",
    "plt_fcst(fcst_hist.iloc[:,[0]], fcst_new.iloc[:,[0]].copy(), fcst_error.iloc[2,[0]].values, \"{0:.0f}%\".format(float(fcst_error.iloc[0,[0]]) * 100),\n",
    "         float(fcst_error.iloc[1,[0]]), fcst_error.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forecasts for the bottom hierarcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_df, mid_df, mid_list, mid_cnt, low_dfs, low_lists, low_cnts = data_split(df)\n",
    "plt.close()\n",
    "\n",
    "for i in range(0, mid_cnt):\n",
    "    mid = mid_list[i]\n",
    "    lows = low_cnts[\"low_cnt\"+str(i)]\n",
    "    \n",
    "    for j in range(0, lows):\n",
    "        low = low_lists[\"low_list\"+str(i)][j]\n",
    "        low_df = low_dfs[\"low_df\"+str(i)].iloc[:,[j+1]]\n",
    "        history, forecast, low_cache, error = run_fcst(low_df,override_fcst=False,override_seasonality=False,plot=True)\n",
    "        \n",
    "        mid_fcst[low] = history.append(forecast, sort=True)\n",
    "        fcst_error[low] = error\n",
    "        fcst_cache[low] = low_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#override_name = 'ov_name'\n",
    "#override_df = low_dfs[\"low_dfX\"].loc[:,[override_name]]\n",
    "#history, forecast, low_cache, error = run_fcst(override_df,override_fcst='NA',override_seasonality=False,plot=True)\n",
    "        \n",
    "#mid_fcst[override_name] = history.append(forecast, sort=True)\n",
    "#fcst_error[override_name] = error\n",
    "#fcst_cache[override_name] = low_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-down reallocation of the middle hierarcy to the bottom hierarcy (replacing origional forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, mid_cnt):\n",
    "    mid = mid_list[i]\n",
    "    lows = low_cnts[\"low_cnt\"+str(i)]\n",
    "    top_index = i + 1\n",
    "    top = mid_fcst.columns[top_index]\n",
    "    \n",
    "    if lows == 1:\n",
    "        pass\n",
    "    else:\n",
    "        bot_f = mid_fcst.columns.get_loc(low_dfs[\"low_df\"+str(i)].columns[1])\n",
    "        bot_l = mid_fcst.columns.get_loc(low_dfs[\"low_df\"+str(i)].columns[low_cnts[\"low_cnt\"+str(i)]]) + 1\n",
    "\n",
    "        new_fcst, error = allocate_fcst(mid_fcst, fcst_cache, fcst_error, top_index, bot_f, bot_l, topdown=True)\n",
    "\n",
    "        fcst_hist = new_fcst[:new_fcst.index.size - 24].copy()\n",
    "        fcst_new  = new_fcst[new_fcst.index.size - 24:].copy()\n",
    "\n",
    "        #is the +1 needed?\n",
    "        for j in range(bot_f, bot_l):\n",
    "            mid_fcst.iloc[:,[j]] = fcst_hist.iloc[:,[j-1]].append(fcst_new.iloc[:,[j-1]])\n",
    "            fcst_error.iloc[:,[j]] = error.iloc[:,[j]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"Forecast_Export.xlsx\", engine='xlsxwriter',datetime_format='MMM-yyyy')\n",
    "\n",
    "mid_fcst.to_excel(writer,'DataExport')\n",
    "fcst_error.T.to_excel(writer,'ErrorExport')\n",
    "\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fcst)",
   "language": "python",
   "name": "fcst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
